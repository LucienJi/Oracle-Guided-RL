# @package _global_
# Base SIMBA Configuration for MetaWorld
seed: 42
method_name: "Simba_Metaworld_Learner"
# Default environment configuration (will be overridden by specific environments)
save_video_fps: 30
env:
  env_name: "assembly-v3"
  camera_to_render: "corner4"
  render_size: [128, 128]
  n_sub_steps: 1
  seed: ${seed}
  reward_scale: 10.0
  step_penality: 0.01
  sparse_reward: false

# Observation configuration (list shapes will be converted to tuples in code)
obs_config:
  robot_states: [39]     # Robot state observations

run_name: ${method_name}_${env.env_name}_seed${seed}

# Base training parameters
training:
  total_timesteps: 1000000
  run_name: ${run_name}
  checkpoint_dir: "./checkpoints/${run_name}"
  results_root_dir: ./results
  seed: ${seed}
  
  # Replay buffer parameters
  replay_dir: "./checkpoints/${run_name}/replay_buffer"
  capacity: 1000000
  nstep: 1
  discount: 0.99
  
  ## SIMBA specific parameters
  learning_starts: 5000
  batch_size: 512
  utd_ratio: 2
  
  ## Soft update parameters
  tau: 0.005
  
  ## Policy parameters
  max_exploration_std: 0.25
  min_exploration_std: 0.01
  exploration_decay_steps: 800000
  target_policy_std: 0.2
  policy_delay: 2
  
  ## Normalization parameters
  normalize_observations: true
  normalize_rewards: true
  normalized_g_max: 5.0
  normalize_network: true
  
  ## Categorical critic parameters
  num_bins: 101
  min_v: -5.0
  max_v: 5.0
  
  ## Optimizer parameters
  actor_lr: 3e-4
  critic_lr: 3e-4
  weight_decay: 1e-4
  max_grad_norm: 1.0
  
  ## Performance options
  use_compile: true
  
  # Evaluation and logging parameters
  eval_every: 10000
  eval_episodes: 10
  save_video_every: 100000
  save_freq: 1000
  save_video_fps: 30
  resume: true
  use_wandb: true
  save_video: true
  wandb_project_name: "MW_Oracles"
  wandb_entity: "jingtianji"
  wandb_group: ${method_name}
  save_episodes_to_disk: true
  keep_checkpoint_num: 5

# SIMBA Actor configuration
rl_agent_args:
  hidden_dim: 256
  num_blocks: 2
  scaler_init: 0.3
  scaler_scale: 1.0
  alpha_init: 0.3
  alpha_scale: 1.0
  c_shift: 4.0
  noise_clip: 0.5
  action_dim: 4
  action_high: [1.0, 1.0, 1.0, 1.0]
  action_low: [-1.0, -1.0, -1.0, -1.0]

# SIMBA Critic configuration  
rl_critic_args:
  hidden_dim: 256
  num_blocks: 2
  scaler_init: 0.3
  scaler_scale: 1.0
  alpha_init: 0.3
  alpha_scale: 1.0
  c_shift: 4.0
  num_bins: ${training.num_bins}
  min_v: ${training.min_v}
  max_v: ${training.max_v}
  num_qs: 2
