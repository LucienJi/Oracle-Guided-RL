# @package _global_
# Base LOKI (off-policy DDPG) configuration for DMC environments.
defaults:
  - /oracles/simba_based_oracle_args
  - /oracles/mlp_based_oracle_args

seed: 42
save_video_fps: 30

env:
  render_size: [128, 128]
  n_sub_steps: 1
  seed: ${seed}

training:
  # Core training
  run_name: ${run_name}
  checkpoint_dir: ./checkpoints/${run_name}
  results_root_dir: ./results
  seed: ${seed}
  total_timesteps: 1000000
  replay_dir: ./checkpoints/${run_name}/replay_buffer
  capacity: 1000000
  nstep: 1
  discount: 0.99
  tau: 0.005
  save_episodes_to_disk: true

  # LOKI phases / DDPG
  learning_starts: 20000
  learner_critic_utd_ratio: 2
  learner_critic_batch_size: 1024
  min_exploration_noise: 0.01
  max_exploration_noise: 0.2
  target_policy_noise: 0.1
  task_specific_noise: 0.1
  noise_clip: 0.3
  policy_delay: 2
  policy_max_grad_norm: 1.0
  loki_N_min: 60000
  loki_N_max: 60000

  # Oracles
  n_oracles: 3
  oracle_std_multiplier: [0.2, 0.2, 0.2]

  # Optimizer
  actor_lr: 3e-4
  critic_lr: 3e-4
  actor_weight_decay: 1e-4
  critic_weight_decay: 1e-4
  max_grad_norm: 1.0

  # Evaluation / logging
  eval_every: 10000
  eval_episodes: 10
  save_freq: 5000
  save_video: true
  save_video_every: 100000
  save_video_fps: ${save_video_fps}
  resume: true
  use_wandb: true
  wandb_project_name: DMC
  wandb_entity: jingtianji
  wandb_group: ${method_name}
  log_every: 100
  keep_checkpoint_num: 5

  # Compilation
  use_compile: true

  # Distributional critic settings (Simba)
  num_bins: 101
  min_v: -5.0
  max_v: 5.0

# Simba actor (deterministic)
rl_agent_args:
  hidden_dim: 256
  num_blocks: 2
  scaler_init: 0.3
  scaler_scale: 1.0
  alpha_init: 0.3
  alpha_scale: 1.0
  c_shift: 4.0
  noise_clip: ${training.noise_clip}

# Simba critic (distributional)
rl_critic_args:
  hidden_dim: 256
  num_blocks: 2
  scaler_init: 0.3
  scaler_scale: 1.0
  alpha_init: 0.3
  alpha_scale: 1.0
  c_shift: 4.0
  num_bins: ${training.num_bins}
  min_v: ${training.min_v}
  max_v: ${training.max_v}
  num_qs: 2


